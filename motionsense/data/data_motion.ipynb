{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd0d98adb0ea4a090799657e464d985c8879f4575dd89b168d44e006b042b3b2d36",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dataset_builder as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACT_LABELS = [\"dws\",\"ups\", \"wlk\", \"jog\", \"std\", \"sit\"]\n",
    "TRIAL_CODES = {\n",
    "    ACT_LABELS[0]:[1,2,11],\n",
    "    ACT_LABELS[1]:[3,4,12],\n",
    "    ACT_LABELS[2]:[7,8,15],\n",
    "    ACT_LABELS[3]:[9,16],\n",
    "    ACT_LABELS[4]:[6,14],\n",
    "    ACT_LABELS[5]:[5,13]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "import keras \n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Sequential, Model, load_model, model_from_json \n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, Concatenate,  Dropout \n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from scipy.signal import resample\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: float(majority/count) for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog', 'std', 'sit']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "         userAcceleration.x  userAcceleration.y  userAcceleration.z  act  \\\n",
      "0                  1.036789            0.485275            0.345870  0.0   \n",
      "1                  0.972504            0.692962            0.082611  0.0   \n",
      "2                  0.770325            0.784256           -0.200515  0.0   \n",
      "3                  0.752320            0.784576            0.053818  0.0   \n",
      "4                  0.959503            1.001206           -0.102829  0.0   \n",
      "...                     ...                 ...                 ...  ...   \n",
      "1412860           -0.647613            0.365982            0.659912  5.0   \n",
      "1412861           -0.648499            0.371307            0.664672  5.0   \n",
      "1412862           -0.648300            0.372711            0.666840  5.0   \n",
      "1412863           -0.647308            0.368728            0.669662  5.0   \n",
      "1412864           -0.646241            0.367614            0.669098  5.0   \n",
      "\n",
      "           id  weight  height   age  gender  trial  \n",
      "0         0.0   102.0   188.0  46.0     1.0    1.0  \n",
      "1         0.0   102.0   188.0  46.0     1.0    1.0  \n",
      "2         0.0   102.0   188.0  46.0     1.0    1.0  \n",
      "3         0.0   102.0   188.0  46.0     1.0    1.0  \n",
      "4         0.0   102.0   188.0  46.0     1.0    1.0  \n",
      "...       ...     ...     ...   ...     ...    ...  \n",
      "1412860  23.0    74.0   173.0  18.0     0.0   13.0  \n",
      "1412861  23.0    74.0   173.0  18.0     0.0   13.0  \n",
      "1412862  23.0    74.0   173.0  18.0     0.0   13.0  \n",
      "1412863  23.0    74.0   173.0  18.0     0.0   13.0  \n",
      "1412864  23.0    74.0   173.0  18.0     0.0   13.0  \n",
      "\n",
      "[1412865 rows x 10 columns]\n",
      "[INFO] -- Shape of time-Series dataset:(1412865, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(1081446, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(331419, 10)\n"
     ]
    }
   ],
   "source": [
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "sdt = [\"userAcceleration\"]\n",
    "mode = \"raw\" #\"mag\"\n",
    "cga = True # Add gravity to acceleration or not\n",
    "print(\"[INFO] -- Selected sensor data types: \"+str(sdt)+\" -- Mode: \"+str(mode)+\" -- Grav+Acc: \"+str(cga))    \n",
    "\n",
    "act_labels = ACT_LABELS [0:6]\n",
    "print(\"[INFO] -- Selected activites: \"+str(act_labels))    \n",
    "trial_codes = [TRIAL_CODES[act] for act in act_labels]\n",
    "dt_list = db.set_data_types(sdt)\n",
    "dataset = db.creat_time_series(dt_list, act_labels, trial_codes, mode=mode, labeled=True, combine_grav_acc = cga)\n",
    "print(\"[INFO] -- Shape of time-Series dataset:\"+str(dataset.shape))\n",
    "\n",
    "test_trail = [11,12,13,14,15,16]  \n",
    "print(\"[INFO] -- Test Trials: \"+str(test_trail))\n",
    "test_ts = dataset.loc[(dataset['trial'].isin(test_trail))]\n",
    "train_ts = dataset.loc[~(dataset['trial'].isin(test_trail))]\n",
    "    \n",
    "print(\"[INFO] -- Shape of Train Time-Series :\"+str(train_ts.shape))\n",
    "print(\"[INFO] -- Shape of Test Time-Series :\"+str(test_ts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         userAcceleration.x  userAcceleration.y  userAcceleration.z  act  \\\n0                  1.036789            0.485275            0.345870  0.0   \n1                  0.972504            0.692962            0.082611  0.0   \n2                  0.770325            0.784256           -0.200515  0.0   \n3                  0.752320            0.784576            0.053818  0.0   \n4                  0.959503            1.001206           -0.102829  0.0   \n...                     ...                 ...                 ...  ...   \n1070113            0.071335            1.003387           -0.122117  4.0   \n1070114            0.077011            1.013885           -0.115311  4.0   \n1070115            0.043564            1.009857           -0.122742  4.0   \n1070116            0.033417            1.006408           -0.127670  4.0   \n1070117            0.018799            0.994629           -0.132629  4.0   \n\n           id  weight  height   age  gender  trial  \n0         0.0   102.0   188.0  46.0     1.0    1.0  \n1         0.0   102.0   188.0  46.0     1.0    1.0  \n2         0.0   102.0   188.0  46.0     1.0    1.0  \n3         0.0   102.0   188.0  46.0     1.0    1.0  \n4         0.0   102.0   188.0  46.0     1.0    1.0  \n...       ...     ...     ...   ...     ...    ...  \n1070113  23.0    74.0   173.0  18.0     0.0    6.0  \n1070114  23.0    74.0   173.0  18.0     0.0    6.0  \n1070115  23.0    74.0   173.0  18.0     0.0    6.0  \n1070116  23.0    74.0   173.0  18.0     0.0    6.0  \n1070117  23.0    74.0   173.0  18.0     0.0    6.0  \n\n[846789 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "mvnts = np.unique(train_ts['act']))\n",
    "gender = np.unique(train_ts['gender']))\n",
    "person = np.unique(train_ts['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_holder = {}\n",
    " \n",
    "for m,i in enumerate(mvnts):\n",
    "    for p,j in enumerate(person):\n",
    "        l = m+p\n",
    "        var_holder['x_'+ str(l)] = train_ts\n",
    "\n",
    " \n",
    "locals().update(var_holder)\n",
    " \n",
    "print(var_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if row[4] == '71':\n",
    "                                x1=row[0]\n",
    "                                x_std_71.append(x1)\n",
    "                                x2=row[1]\n",
    "                                x_std_71.append(x2)\n",
    "                                x3= row[2]\n",
    "                                x_std_71.append(x3)\n",
    "                                y_std_71.append(mvts.index(row[3]))\n",
    "                                p_std_71.append(id.index(row[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp=(x_j_0.shape)[0]\n",
    "shape_y = y_j_0.shape[0]\n",
    "shape_p =  p_j_0.shape[0]\n",
    "nece_shp = biggest_multiple((segement_time_size*sensors),shp)\n",
    "if shp >= nece_shp:\n",
    "    x_j_0 =  np.delete(x_j_0, [k for k in range(nece_shp,shp)], None)\n",
    "x_j_0 = x_j_0.reshape(-1,sensors)\n",
    "shape_x_j_0 = x_j_0.shape[0]\n",
    "x_j_0 = preprocessing.normalize(x_j_0, axis=0)\n",
    "x_j_0= np.reshape(x_j_0, (-1,segement_time_size, sensors))\n",
    "y_j_0 = np.delete(y_j_0, [k for k in range(x_j_0.shape[0],shape_y)], None)\n",
    "p_j_0 = np.delete(p_j_0,[k for k in range(x_j_0.shape[0],shape_p)], None)\n",
    "y= np.concatenate((y,y_j_0), axis=0)\n",
    "p= np.concatenate((p,p_j_0), axis=0)\n",
    "print(y)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot= to_categorical(np.array(y))\n",
    "p_onehot = to_categorical(np.array(p))\n",
    "h5f = h5py.File('RL_acc_hasc_data_a_p.h5', 'w')\n",
    "h5f.create_dataset('X', data=x_j_0)\n",
    "h5f.create_dataset('y', data=y)\n",
    "h5f.create_dataset('p', data=p)\n",
    "h5f.create_dataset('y_onehot', data=y_onehot)\n",
    "h5f.create_dataset('p_onehot', data=p_onehot)\n",
    "h5f.close()"
   ]
  }
 ]
}